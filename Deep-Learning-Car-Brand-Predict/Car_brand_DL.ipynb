{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'Datasets/train'\n",
    "valid_path = 'Datasets/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "# Here we will be using imagenet weights\n",
    "\n",
    "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont train existing weights.\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for folders getting no. of outputs classes.\n",
    "\n",
    "folders = glob('Datasets/train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Datasets/train\\\\audi',\n",
       " 'Datasets/train\\\\lamborghini',\n",
       " 'Datasets/train\\\\mercedes']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want.\n",
    "\n",
    "x = Flatten()(resnet.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "model = Model(inputs=resnet.input, outputs= prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            301059      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,888,771\n",
      "Trainable params: 301,059\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View the structure of the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization to use.\n",
    "model.compile(\n",
    "   loss='categorical_crossentropy',\n",
    "   optimizer= 'adam',\n",
    "   metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True)\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same image size as initialized for the image size.\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Datasets/train',\n",
    "                                                target_size = (224, 224),\n",
    "                                                batch_size = 32,\n",
    "                                                class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('Datasets/test',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-793076fb6ae8>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2 steps, validate for 2 steps\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 46s 23s/step - loss: 4.5517 - accuracy: 0.4844 - val_loss: 7.4848 - val_accuracy: 0.3276\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 3.7178 - accuracy: 0.7500 - val_loss: 11.4803 - val_accuracy: 0.3276\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.7481 - accuracy: 0.9219 - val_loss: 9.6137 - val_accuracy: 0.3276\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 1.0584 - accuracy: 0.9219 - val_loss: 9.5384 - val_accuracy: 0.3276\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 1.2845 - accuracy: 0.9062 - val_loss: 14.0582 - val_accuracy: 0.3276\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.0153e-06 - accuracy: 1.0000 - val_loss: 17.6864 - val_accuracy: 0.3276\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 7.0157e-05 - accuracy: 1.0000 - val_loss: 20.6352 - val_accuracy: 0.3276\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 2.4214e-08 - accuracy: 1.0000 - val_loss: 23.0505 - val_accuracy: 0.3276\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 1.0327e-05 - accuracy: 1.0000 - val_loss: 25.0380 - val_accuracy: 0.3276\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 26.7873 - val_accuracy: 0.3276\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.4442 - accuracy: 0.9844 - val_loss: 28.2897 - val_accuracy: 0.3276\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 41s 20s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 29.4840 - val_accuracy: 0.3276\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.0286 - accuracy: 0.9844 - val_loss: 30.3014 - val_accuracy: 0.3276\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.1127 - accuracy: 0.9844 - val_loss: 30.6511 - val_accuracy: 0.3276\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 30.6643 - val_accuracy: 0.3276\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.6703 - val_accuracy: 0.3276\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 6.7561e-05 - accuracy: 1.0000 - val_loss: 30.6729 - val_accuracy: 0.3276\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 39s 19s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.6750 - val_accuracy: 0.3276\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 39s 19s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.6768 - val_accuracy: 0.3276\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 39s 19s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.6783 - val_accuracy: 0.3276\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 39s 19s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.6795 - val_accuracy: 0.3276\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.6805 - val_accuracy: 0.3276\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.0194 - accuracy: 0.9844 - val_loss: 30.4757 - val_accuracy: 0.3276\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.1195 - val_accuracy: 0.3276\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 29.8252 - val_accuracy: 0.3276\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 39s 19s/step - loss: 1.8626e-09 - accuracy: 1.0000 - val_loss: 29.5821 - val_accuracy: 0.3276\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.0445 - accuracy: 0.9844 - val_loss: 30.0133 - val_accuracy: 0.3276\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.3690 - val_accuracy: 0.3276\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 3.6880e-07 - accuracy: 1.0000 - val_loss: 30.6623 - val_accuracy: 0.3276\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 1.8626e-09 - accuracy: 1.0000 - val_loss: 30.9040 - val_accuracy: 0.3276\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 9.1269e-08 - accuracy: 1.0000 - val_loss: 31.1032 - val_accuracy: 0.3276\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 6.8918e-08 - accuracy: 1.0000 - val_loss: 31.2671 - val_accuracy: 0.3276\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 39s 19s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 31.4020 - val_accuracy: 0.3276\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 31.5130 - val_accuracy: 0.3276\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 39s 19s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 31.6042 - val_accuracy: 0.3276\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 39s 19s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 31.6792 - val_accuracy: 0.3276\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 31.7408 - val_accuracy: 0.3276\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 39s 20s/step - loss: 1.8626e-09 - accuracy: 1.0000 - val_loss: 31.7914 - val_accuracy: 0.3276\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 31.5771 - val_accuracy: 0.3276\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 31.1695 - val_accuracy: 0.3276\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 42s 21s/step - loss: 7.6983e-06 - accuracy: 1.0000 - val_loss: 30.8375 - val_accuracy: 0.3276\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 41s 20s/step - loss: 5.5874e-05 - accuracy: 1.0000 - val_loss: 30.5661 - val_accuracy: 0.3276\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.3443 - val_accuracy: 0.3276\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 41s 20s/step - loss: 0.0724 - accuracy: 0.9844 - val_loss: 30.7167 - val_accuracy: 0.3276\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 41s 21s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 31.0220 - val_accuracy: 0.3276\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.1479 - accuracy: 0.9844 - val_loss: 30.9547 - val_accuracy: 0.3276\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 41s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.6123 - val_accuracy: 0.3276\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 9.3132e-09 - accuracy: 1.0000 - val_loss: 30.3319 - val_accuracy: 0.3276\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.1023 - val_accuracy: 0.3276\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 40s 20s/step - loss: 5.4017e-08 - accuracy: 1.0000 - val_loss: 29.9144 - val_accuracy: 0.3276\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. it will take time to execute.\n",
    "r = model.fit_generator(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_steps=len(test_set)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [4.551668405532837,\n",
       "  3.7178425788879395,\n",
       "  0.7480554264038801,\n",
       "  1.0584211629284255,\n",
       "  1.284462974557755,\n",
       "  4.015347258246038e-06,\n",
       "  7.015682604105677e-05,\n",
       "  2.421437972355278e-08,\n",
       "  1.0326543815608602e-05,\n",
       "  0.00826809270074591,\n",
       "  0.4441645298347794,\n",
       "  0.006244972348213085,\n",
       "  0.028645107777265366,\n",
       "  0.11266440338363282,\n",
       "  0.004211263381876051,\n",
       "  0.0,\n",
       "  6.756087532266974e-05,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.019362488753529306,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.8626450382086546e-09,\n",
       "  0.04453746974468231,\n",
       "  0.0,\n",
       "  3.687995873136174e-07,\n",
       "  1.8626450382086546e-09,\n",
       "  9.12693423060773e-08,\n",
       "  6.89177213075709e-08,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.8626450382086546e-09,\n",
       "  0.008746889419853687,\n",
       "  0.0,\n",
       "  7.69827875046758e-06,\n",
       "  5.587433042819612e-05,\n",
       "  0.0,\n",
       "  0.07241040468215942,\n",
       "  0.0,\n",
       "  0.1478853076696396,\n",
       "  0.0,\n",
       "  9.313223081619526e-09,\n",
       "  0.0,\n",
       "  5.4016616957142105e-08],\n",
       " 'accuracy': [0.484375,\n",
       "  0.75,\n",
       "  0.921875,\n",
       "  0.921875,\n",
       "  0.90625,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'val_loss': [7.484775066375732,\n",
       "  11.480263710021973,\n",
       "  9.613718032836914,\n",
       "  9.538383483886719,\n",
       "  14.058244705200195,\n",
       "  17.686386108398438,\n",
       "  20.635211944580078,\n",
       "  23.050472259521484,\n",
       "  25.03800868988037,\n",
       "  26.787275314331055,\n",
       "  28.28966522216797,\n",
       "  29.484046936035156,\n",
       "  30.30142116546631,\n",
       "  30.651079177856445,\n",
       "  30.664304733276367,\n",
       "  30.67031764984131,\n",
       "  30.672903060913086,\n",
       "  30.675048828125,\n",
       "  30.676827430725098,\n",
       "  30.678302764892578,\n",
       "  30.679521560668945,\n",
       "  30.68053150177002,\n",
       "  30.475749015808105,\n",
       "  30.119513511657715,\n",
       "  29.825173377990723,\n",
       "  29.582118034362793,\n",
       "  30.013325691223145,\n",
       "  30.3690128326416,\n",
       "  30.662309646606445,\n",
       "  30.90403938293457,\n",
       "  31.103151321411133,\n",
       "  31.267101287841797,\n",
       "  31.40201473236084,\n",
       "  31.512990951538086,\n",
       "  31.60423183441162,\n",
       "  31.679219245910645,\n",
       "  31.74083137512207,\n",
       "  31.791433334350586,\n",
       "  31.57713031768799,\n",
       "  31.16946315765381,\n",
       "  30.83749485015869,\n",
       "  30.566081047058105,\n",
       "  30.344308853149414,\n",
       "  30.71672534942627,\n",
       "  31.02196216583252,\n",
       "  30.95469379425049,\n",
       "  30.61233901977539,\n",
       "  30.331936836242676,\n",
       "  30.10233497619629,\n",
       "  29.9143648147583],\n",
       " 'val_accuracy': [0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train_acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it as h5 file\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model.save('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.35046639e-21, 4.28487247e-20, 1.00000000e+00],\n",
       "       [7.42403970e-21, 1.42364876e-20, 1.00000000e+00],\n",
       "       [1.97136648e-21, 3.04986791e-20, 1.00000000e+00],\n",
       "       [3.00273146e-21, 4.28046160e-20, 1.00000000e+00],\n",
       "       [1.40401727e-20, 2.31980244e-19, 1.00000000e+00],\n",
       "       [4.26596792e-21, 9.94975234e-20, 1.00000000e+00],\n",
       "       [9.26216346e-21, 1.03865593e-19, 1.00000000e+00],\n",
       "       [3.10499348e-21, 7.33715924e-20, 1.00000000e+00],\n",
       "       [2.22851537e-20, 2.34938707e-19, 1.00000000e+00],\n",
       "       [3.51631207e-21, 2.00995893e-19, 1.00000000e+00],\n",
       "       [4.58678274e-21, 7.71672141e-20, 1.00000000e+00],\n",
       "       [1.57496340e-21, 2.48557660e-20, 1.00000000e+00],\n",
       "       [2.15355035e-20, 3.18371426e-19, 1.00000000e+00],\n",
       "       [7.63735456e-21, 8.09915673e-20, 1.00000000e+00],\n",
       "       [3.71611981e-21, 1.23733179e-19, 1.00000000e+00],\n",
       "       [5.43104616e-21, 8.67098152e-20, 1.00000000e+00],\n",
       "       [3.56339795e-21, 1.14051404e-19, 1.00000000e+00],\n",
       "       [6.55901921e-21, 2.09583876e-19, 1.00000000e+00],\n",
       "       [1.62790599e-20, 1.47813802e-19, 1.00000000e+00],\n",
       "       [2.01953319e-21, 4.53291518e-20, 1.00000000e+00],\n",
       "       [2.89397336e-21, 7.49984499e-20, 1.00000000e+00],\n",
       "       [1.06964914e-20, 9.79022862e-20, 1.00000000e+00],\n",
       "       [1.58626358e-20, 2.99021811e-19, 1.00000000e+00],\n",
       "       [2.14918438e-20, 4.01264979e-19, 1.00000000e+00],\n",
       "       [3.93439088e-20, 4.40795863e-19, 1.00000000e+00],\n",
       "       [2.53508369e-20, 2.33379988e-19, 1.00000000e+00],\n",
       "       [2.06915292e-21, 3.56417456e-20, 1.00000000e+00],\n",
       "       [2.02593758e-21, 1.78937196e-20, 1.00000000e+00],\n",
       "       [4.95809474e-21, 3.64442801e-19, 1.00000000e+00],\n",
       "       [1.69230157e-21, 1.44448014e-20, 1.00000000e+00],\n",
       "       [9.11738424e-21, 6.87736314e-20, 1.00000000e+00],\n",
       "       [6.21879676e-21, 1.49855426e-19, 1.00000000e+00],\n",
       "       [4.72412218e-21, 4.78234600e-20, 1.00000000e+00],\n",
       "       [8.41186087e-22, 1.36913061e-20, 1.00000000e+00],\n",
       "       [8.29678714e-21, 2.30937479e-19, 1.00000000e+00],\n",
       "       [2.34417452e-21, 4.06330989e-20, 1.00000000e+00],\n",
       "       [3.59359368e-21, 5.99433427e-20, 1.00000000e+00],\n",
       "       [3.99842023e-21, 5.03262307e-20, 1.00000000e+00],\n",
       "       [8.74438717e-21, 5.21148537e-20, 1.00000000e+00],\n",
       "       [4.69446051e-22, 6.48478056e-21, 1.00000000e+00],\n",
       "       [3.91110461e-21, 4.76450120e-20, 1.00000000e+00],\n",
       "       [8.16716051e-21, 5.40733750e-20, 1.00000000e+00],\n",
       "       [2.31695228e-21, 6.51396525e-20, 1.00000000e+00],\n",
       "       [1.40819050e-20, 2.18179795e-19, 1.00000000e+00],\n",
       "       [5.45513214e-21, 6.15688495e-20, 1.00000000e+00],\n",
       "       [1.09351601e-21, 7.03639734e-21, 1.00000000e+00],\n",
       "       [1.85278344e-20, 1.55311664e-19, 1.00000000e+00],\n",
       "       [3.13257115e-21, 3.81969001e-20, 1.00000000e+00],\n",
       "       [5.13135192e-21, 1.16941496e-19, 1.00000000e+00],\n",
       "       [1.27611156e-20, 2.19004494e-19, 1.00000000e+00],\n",
       "       [7.00215093e-21, 2.86816011e-19, 1.00000000e+00],\n",
       "       [1.02955037e-21, 1.68489469e-20, 1.00000000e+00],\n",
       "       [1.77455222e-21, 2.25518015e-20, 1.00000000e+00],\n",
       "       [3.88770647e-21, 2.65273462e-20, 1.00000000e+00],\n",
       "       [3.30330720e-21, 4.00093982e-20, 1.00000000e+00],\n",
       "       [1.01832456e-21, 2.29672271e-20, 1.00000000e+00],\n",
       "       [3.73329794e-21, 6.87560603e-20, 1.00000000e+00],\n",
       "       [1.89252805e-21, 4.79928737e-20, 1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('Datasets/Test/lamborghini/11.jpg', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.keras.preprocessing.image' from 'C:\\\\Users\\\\Admin\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow_core\\\\python\\\\keras\\\\api\\\\_v2\\\\keras\\\\preprocessing\\\\image\\\\__init__.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [196., 187., 172.],\n",
       "        [217., 208., 193.],\n",
       "        [243., 234., 219.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [245., 245., 237.],\n",
       "        [243., 243., 235.],\n",
       "        [242., 242., 234.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [240., 249., 248.],\n",
       "        [242., 251., 250.],\n",
       "        [242., 251., 250.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[189., 207., 229.],\n",
       "        [190., 206., 229.],\n",
       "        [190., 206., 229.],\n",
       "        ...,\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        ...,\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        ...,\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         ...,\n",
       "         [-103.264496, -116.04567 , -122.91137 ],\n",
       "         [-103.18214 , -115.96331 , -122.82902 ],\n",
       "         [-103.08018 , -115.86135 , -122.72706 ]],\n",
       "\n",
       "        [[-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         ...,\n",
       "         [-103.00959 , -115.818214, -122.719215],\n",
       "         [-103.01743 , -115.82606 , -122.72706 ],\n",
       "         [-103.021355, -115.82998 , -122.73098 ]],\n",
       "\n",
       "        [[-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         [-102.95077 , -115.790764, -122.691765],\n",
       "         ...,\n",
       "         [-102.96645 , -115.80253 , -122.73882 ],\n",
       "         [-102.95861 , -115.794685, -122.73098 ],\n",
       "         [-102.95861 , -115.794685, -122.73098 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-103.04096 , -115.96723 , -122.93883 ],\n",
       "         [-103.04096 , -115.97115 , -122.934906],\n",
       "         [-103.04096 , -115.97115 , -122.934906],\n",
       "         ...,\n",
       "         [-103.20567 , -116.07312 , -123.009415],\n",
       "         [-103.20567 , -116.07312 , -123.009415],\n",
       "         [-103.20567 , -116.07312 , -123.009415]],\n",
       "\n",
       "        [[-103.048805, -115.97115 , -122.95451 ],\n",
       "         [-103.048805, -115.97115 , -122.95451 ],\n",
       "         [-103.048805, -115.97115 , -122.95451 ],\n",
       "         ...,\n",
       "         [-103.20567 , -116.07312 , -123.009415],\n",
       "         [-103.20567 , -116.07312 , -123.009415],\n",
       "         [-103.20567 , -116.07312 , -123.009415]],\n",
       "\n",
       "        [[-103.048805, -115.97115 , -122.95451 ],\n",
       "         [-103.048805, -115.97115 , -122.95451 ],\n",
       "         [-103.048805, -115.97115 , -122.95451 ],\n",
       "         ...,\n",
       "         [-103.20567 , -116.07312 , -123.009415],\n",
       "         [-103.20567 , -116.07312 , -123.009415],\n",
       "         [-103.20567 , -116.07312 , -123.009415]]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7611111e-14, 2.4287467e-14, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.argmax(model.predict(img_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
